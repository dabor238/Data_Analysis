[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Colección Completa de Análisis de Datos",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html",
    "href": "chapters/optimization/01_intro.html",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "",
    "text": "2.1 Introducción\nEste libro se enfoca en los fundamentos de algoritmos para resolver problemas de optimización continua, que involucran:\nEste capítulo describe varios paradigmas clave de la ciencia de datos y demuestra cómo pueden formularse como problemas de optimización continua. Comprender las propiedades de suavidad y estructura de estas formulaciones es crucial para seleccionar algoritmos apropiados.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-introduction",
    "href": "chapters/optimization/01_intro.html#sec-introduction",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "",
    "text": "Minimizar funciones de múltiples variables de valores reales\nManejar restricciones en los valores de las variables\nEnfatizar problemas convexos con aplicaciones en ciencia de datos\nConectar teoría y práctica en aprendizaje automático, estadística y análisis de datos\n\n\n\n\n\n\n\nImportanteEnfoque Principal\n\n\n\nNuestra selección de temas está motivada por la relevancia para la ciencia de datos — las formulaciones y algoritmos discutidos son directamente útiles para resolver problemas del mundo real en aprendizaje automático, estadística y análisis de datos.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-data-analysis",
    "href": "chapters/optimization/01_intro.html#sec-data-analysis",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.2 Análisis de Datos y Optimización",
    "text": "2.2 Análisis de Datos y Optimización\nEl problema de optimización típico en análisis de datos implica encontrar un modelo que equilibre dos objetivos competitivos:\n\nConcordancia con los datos recopilados\nAdhesión a restricciones estructurales que reflejan nuestras creencias sobre buenos modelos\n\n\n2.2.1 El Marco de Ciencia de Datos\nEn un problema de análisis típico, nuestro conjunto de datos consiste en \\(m\\) objetos:\n\\[D := \\{(a_j, y_j), j = 1,2, \\ldots, m\\} \\tag{2.1}\\]\ndonde:\n\n\nCaracterísticas (\\(a_j\\))\n\nVector o matriz de características\nVariables de entrada\nPredictores\n\n\n\nEtiquetas/Observaciones (\\(y_j\\))\n\nValores objetivo\nRespuestas\nResultados\n\n\n\n\n\n\n\n\n\nTipPreprocesamiento de Datos\n\n\n\nAsumimos que los datos han sido limpiados de modo que todos los pares \\((a_j, y_j)\\) tienen tamaño y forma consistentes.\n\n\n\n\n2.2.2 El Objetivo de Aprendizaje\nLa tarea de análisis de datos consiste en descubrir una función \\(\\phi\\) tal que:\n\\[\\phi(a_j) \\approx y_j \\quad \\text{para la mayoría } j = 1,2, \\ldots, m\\]\n\n\n\n\n\n\nNotaTerminología\n\n\n\nEl proceso de descubrir el mapeo \\(\\phi\\) se suele llamar “aprendizaje” o “entrenamiento”.\n\n\n\n\n2.2.3 Parametrización y Formulación de Optimización\nLa función \\(\\phi\\) a menudo se define en términos de un vector o matriz de parámetros, que denotamos por \\(x\\) o \\(X\\). Con estas parametrizaciones, el problema de identificar \\(\\phi\\) se convierte en un problema tradicional de ajuste de datos:\n\n\n\n\n\n\nTipObjetivo de Optimización\n\n\n\nEncontrar los parámetros \\(x\\) que definen \\(\\phi\\) tal que \\(\\phi(a_j) \\approx y_j\\) para \\(j = 1,2, \\ldots, m\\) en algún sentido óptimo.\n\n\nUna vez que definimos “óptimo” (y posiblemente agregamos restricciones en los valores permitidos de los parámetros), tenemos un problema de optimización.\n\n\n2.2.4 Formulación de Suma Finita\nFrecuentemente, estas formulaciones de optimización tienen funciones objetivo del tipo suma finita:\n\\[L_D(x) := \\frac{1}{m} \\sum_{j=1}^{m} \\ell(a_j, y_j; x) \\tag{2.2}\\]\ndonde:\n\n\\(\\ell(a,y;x)\\) representa la “pérdida” incurrida por no alinear correctamente nuestra predicción \\(\\phi(a)\\) con \\(y\\)\n\\(L_D(x)\\) mide la pérdida promedio acumulada sobre todo el conjunto de datos cuando el vector de parámetros es igual a \\(x\\)\n\n\n\n2.2.5 Predicción y Propiedades del Modelo\nUna vez que se ha aprendido un valor apropiado de \\(x\\) (y por lo tanto \\(\\phi\\)) de los datos, podemos usarlo para hacer predicciones sobre otros elementos de datos que no están en el conjunto \\(D\\) (Ecuación 2.1).\nDado un elemento de datos no visto \\(\\hat{a}\\) del mismo tipo que \\(a_j\\), \\(j = 1,2, \\ldots, m\\), predecimos que la etiqueta \\(\\hat{y}\\) asociada con \\(\\hat{a}\\) será \\(\\phi(\\hat{a})\\).\nEl mapeo \\(\\phi\\) también puede exponer otras estructuras y propiedades en el conjunto de datos:\n\nSelección de Características: Revela que solo una pequeña fracción de las características en \\(a_j\\) son necesarias para predecir confiablemente la etiqueta \\(y_j\\)\nDescubrimiento de Subespacios: Cuando el parámetro \\(x\\) es una matriz, podría revelar un subespacio de baja dimensión que contiene la mayoría de los vectores \\(a_j\\)\nMatrices Estructuradas: Podría revelar una matriz con estructura particular (bajo rango, dispersa) tal que las observaciones de \\(X\\) motivadas por los vectores de características \\(a_j\\) produzcan resultados cercanos a \\(y_j\\)\n\n\n\n2.2.6 Tipos de Problemas de Análisis de Datos\nLa forma de las etiquetas \\(y_j\\) difiere según la naturaleza del problema de análisis de datos:\n\nRegresiónClasificaciónAprendizaje No Supervisado\n\n\nSi cada \\(y_j\\) es un número real, típicamente tenemos un problema de regresión.\n\n\nCuando cada \\(y_j\\) es una etiqueta (un entero del conjunto \\(\\{1,2, \\ldots, M\\}\\)) indicando que \\(a_j\\) pertenece a una de \\(M\\) clases:\n\nClasificación Binaria: \\(M = 2\\)\nClasificación Multiclase: \\(M &gt; 2\\)\n\n\n\n\n\n\n\nNota\n\n\n\nEn problemas de análisis de datos que surgen en reconocimiento de voz e imagen, \\(M\\) puede ser muy grande, del orden de miles o más.\n\n\n\n\nLas etiquetas \\(y_j\\) pueden ni siquiera existir; el conjunto de datos puede contener solo los vectores de características \\(a_j\\), \\(j = 1,2, \\ldots, m\\). Todavía hay problemas interesantes de análisis de datos asociados con estos casos. Por ejemplo, podemos desear agrupar los \\(a_j\\) en clústeres (donde los vectores dentro de cada clúster se consideran funcionalmente similares) o identificar un subespacio de baja dimensión (o una colección de subespacios de baja dimensión) que aproximadamente contenga los \\(a_j\\).\nEn tales problemas, esencialmente estamos aprendiendo las etiquetas \\(y_j\\) junto con la función \\(\\phi\\). Por ejemplo, en un problema de clustering, \\(y_j\\) podría representar el clúster al cual se asigna \\(a_j\\).\n\n\n\n\n\n2.2.7 Complicaciones de Datos y Robustez\nIncluso después de la limpieza y preparación, la configuración anterior puede contener muchas complicaciones:\n\nRuido y Corrupción: Las cantidades \\((a_j,y_j)\\) pueden contener ruido o estar corrompidas de otra manera, requiriendo que el mapeo \\(\\phi\\) sea robusto a tales errores\nDatos Faltantes: Partes de los vectores \\(a_j\\) pueden estar faltando, o podemos no conocer todas las etiquetas \\(y_j\\)\nDatos en Flujo: Los datos pueden estar llegando de forma continua en lugar de estar disponibles todos a la vez, requiriendo aprendizaje en línea de \\(\\phi\\)\n\n\n\n2.2.8 Regularization and Overfitting\nOne consideration that arises frequently is that we wish to avoid overfitting the model to the data set \\(D\\) in (Ecuación 2.1).\n\n\n\n\n\n\nImportanteGeneralization Goal\n\n\n\nThe particular data set \\(D\\) available to us can often be thought of as a finite sample drawn from some underlying larger (perhaps infinite) collection of possible data points. We wish the function \\(\\phi\\) to perform well on the unobserved data points as well as the observed subset \\(D\\).\n\n\nIn other words, we want \\(\\phi\\) to be not too sensitive to the particular sample \\(D\\) that is used to define empirical objective functions such as (Ecuación 2.2).\nOne way to avoid this issue is to modify the objective function by adding constraints or penalty terms, in a way that limits the “complexity” of the function \\(\\phi\\). This process is typically called regularization.\nAn optimization formulation that balances fit to the training data \\(D\\), model complexity, and model structure is:\n\\[\\min_{x \\in \\Omega} L_D(x) + \\lambda \\text{pen}(x) \\tag{2.3}\\]\nwhere:\n\n\\(\\Omega\\) is a set of allowable values for \\(x\\)\n\\(\\text{pen}(\\cdot)\\) is a regularization function or regularizer\n\\(\\lambda \\geq 0\\) is a regularization parameter\n\nThe regularizer usually takes lower values for parameters \\(x\\) that yield functions \\(\\phi\\) with lower complexity. For example, \\(\\phi\\) may depend on fewer of the features in the data vectors \\(a_j\\) or may be less oscillatory.\n\n2.2.8.1 Ajuste del Parámetro de Regularización\nEl parámetro \\(\\lambda\\) puede ser “ajustado” para proporcionar un equilibrio apropiado:\n\nValores más pequeños de \\(\\lambda\\): Producen soluciones que se ajustan a los datos de entrenamiento \\(D\\) con mayor precisión\nValores más grandes de \\(\\lambda\\): Conducen a modelos menos complejos\n\n\n\n\n\n\n\nNotaPerspectiva Moderna sobre el Sobreajuste\n\n\n\n\n\nCuriosamente, el concepto de sobreajuste ha sido reexaminado en años recientes, particularmente en el contexto del aprendizaje profundo, donde los modelos que se ajustan perfectamente a los datos de entrenamiento a veces se observa que también hacen un buen trabajo al clasificar datos previamente no vistos. Este fenómeno es un tema de intensa investigación actual en la comunidad de aprendizaje automático.\n\n\n\n\n\n2.2.8.2 Conjuntos de Restricciones\nEl conjunto de restricciones \\(\\Omega\\) en (Ecuación 2.3) puede elegirse para excluir valores de \\(x\\) que no son relevantes o útiles en el contexto del problema de análisis de datos. Por ejemplo:\n\nEn algunas aplicaciones, podemos no desear considerar valores de \\(x\\) en los que uno o más componentes sean negativos\nPodríamos establecer \\(\\Omega\\) como el conjunto de vectores cuyos componentes son todos mayores o iguales a cero\n\n\n\n\n2.2.9 Resumen del Marco\nAhora examinamos algunos problemas particulares en ciencia de datos que dan lugar a formulaciones que son casos especiales de nuestro problema maestro (Ecuación 2.3). Veremos que:\n\nUna gran variedad de problemas puede formularse usando este marco general\nDentro de este marco, hay una amplia gama de estructuras que deben tenerse en cuenta al elegir algoritmos para resolver estos problemas de manera eficiente",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-least-squares",
    "href": "chapters/optimization/01_intro.html#sec-least-squares",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.3 Mínimos Cuadrados",
    "text": "2.3 Mínimos Cuadrados\nProbablemente el problema de análisis de datos más antiguo y conocido es el de mínimos cuadrados lineales. Aquí, los puntos de datos \\((a_j,y_j)\\) se encuentran en \\(\\mathbb{R}^n \\times \\mathbb{R}\\), y resolvemos:\n\\[\\min_x \\frac{1}{2m} \\sum_{j=1}^{m} (a_j^T x - y_j)^2 = \\frac{1}{2m} \\|Ax - y\\|_2^2 \\tag{2.4}\\]\ndonde:\n\n\\(A\\) es la matriz cuyas filas son \\(a_j^T\\), \\(j = 1,2, \\ldots, m\\)\n\\(y = (y_1,y_2, \\ldots, y_m)^T\\)\n\nEn la terminología anterior, la función \\(\\phi\\) se define por \\(\\phi(a) := a^T x\\).\n\n\n\n\n\n\nTipAgregar un Intercepto\n\n\n\nPodemos introducir un intercepto no nulo agregando un parámetro adicional \\(\\beta \\in \\mathbb{R}\\) y definiendo \\(\\phi(a) := a^T x + \\beta\\).\n\n\n\n2.3.1 Motivación Estadística\nEsta formulación puede motivarse estadísticamente, como una estimación de máxima verosimilitud de \\(x\\) cuando las observaciones \\(y_j\\) son exactas excepto por ruido Gaussiano independiente e idénticamente distribuido (i.i.d.).\n\n\n2.3.2 Regresión Ridge\nPodemos agregar una variedad de funciones de penalización a este problema básico de mínimos cuadrados para imponer estructura deseable en \\(x\\) y, por lo tanto, en \\(\\phi\\). Por ejemplo, la regresión ridge agrega una penalización de norma \\(\\ell_2\\) al cuadrado:\n\\[\\min_x \\frac{1}{2m} \\|Ax - y\\|_2^2 + \\lambda \\|x\\|_2^2 \\tag{2.5}\\]\npara algún parámetro \\(\\lambda &gt; 0\\). La solución \\(x\\) de esta formulación regularizada tiene menos sensibilidad a perturbaciones en los datos \\((a_j,y_j)\\).\n\n\n2.3.3 Formulación LASSO\nLa formulación LASSO (Least Absolute Shrinkage and Selection Operator):\n\\[\\min_x \\frac{1}{2m} \\|Ax - y\\|_2^2 + \\lambda \\|x\\|_1 \\tag{2.6}\\]\ntiende a producir soluciones \\(x\\) que son dispersas – es decir, que contienen relativamente pocos componentes no nulos.\n\n\n\n\n\n\nImportanteSelección de Características\n\n\n\nEsta formulación realiza selección de características: Las ubicaciones de los componentes no nulos en \\(x\\) revelan aquellos componentes de \\(a_j\\) que son instrumentales para determinar la observación \\(y_j\\).\n\n\n\n2.3.3.1 Ventajas de la Selección de Características\n\nAtractivo Estadístico: Los predictores que dependen de pocas características son potencialmente más simples y más comprensibles que aquellos que dependen de muchas características\nBeneficios Prácticos: En lugar de recopilar todos los componentes de un nuevo vector de datos \\(\\hat{a}\\), solo necesitamos encontrar las características “seleccionadas” porque solo estas son necesarias para hacer una predicción\n\n\n\n\n\n\n\nNotaLASSO como Prototipo\n\n\n\nLa formulación LASSO (Ecuación 2.6) es un prototipo importante para muchos problemas en análisis de datos en el sentido de que involucra un término de regularización \\(\\lambda \\|x\\|_1\\) que es no suave y convexo pero tiene una estructura relativamente simple que puede ser potencialmente explotada por algoritmos.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-matrix-factorization",
    "href": "chapters/optimization/01_intro.html#sec-matrix-factorization",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.4 Problemas de Factorización de Matrices",
    "text": "2.4 Problemas de Factorización de Matrices\nHay una variedad de problemas de análisis de datos que requieren estimar una matriz de bajo rango a partir de alguna colección dispersa de datos. Tales problemas pueden formularse como una extensión natural de mínimos cuadrados a problemas en los que los datos \\(a_j\\) se representan naturalmente como matrices en lugar de vectores.\n\n2.4.1 Problema Básico de Sensado de Matrices\nCambiando ligeramente la notación, suponemos que cada \\(A_j\\) es una matriz \\(n \\times p\\), y buscamos otra matriz \\(n \\times p\\) \\(X\\) que resuelva:\n\\[\\min_X \\frac{1}{2m} \\sum_{j=1}^{m} (\\langle A_j, X \\rangle - y_j)^2 \\tag{2.7}\\]\ndonde \\(\\langle A, B \\rangle := \\text{trace}(A^T B)\\).\nAquí podemos pensar en las \\(A_j\\) como “sondeo” de la matriz desconocida \\(X\\). Los tipos de observaciones comúnmente considerados son:\n\nCombinaciones lineales aleatorias: Los elementos de \\(A_j\\) se seleccionan i.i.d. de alguna distribución\nObservaciones de elementos individuales: Cada \\(A_j\\) tiene 1 en una única ubicación y ceros en otros lugares\n\n\n\n2.4.2 Regularización de Norma Nuclear\nUna versión regularizada de (Ecuación 2.7), que conduce a soluciones \\(X\\) de bajo rango, es:\n\\[\\min_X \\frac{1}{2m} \\sum_{j=1}^{m} (\\langle A_j, X \\rangle - y_j)^2 + \\lambda \\|X\\|_* \\tag{2.8}\\]\ndonde \\(\\|X\\|_*\\) es la norma nuclear, que es la suma de valores singulares de \\(X\\).\n\n\n\n\n\n\nNotaPropiedades de la Norma Nuclear\n\n\n\nLa norma nuclear juega un papel análogo a la norma \\(\\ell_1\\) en (Ecuación 2.6):\n\nLa norma \\(\\ell_1\\) favorece vectores dispersos\nLa norma nuclear favorece matrices de bajo rango\n\n\n\nAunque la norma nuclear es una función no suave algo compleja, es al menos convexa, por lo que la formulación (Ecuación 2.8) también es convexa.\nEsta formulación puede demostrarse que produce una solución estadísticamente válida cuando:\n\nLa verdadera \\(X\\) es de bajo rango\nLas matrices de observación \\(A_j\\) satisfacen una “propiedad de isometría restringida” (comúnmente satisfecha por matrices aleatorias pero no por matrices con solo un elemento no nulo)\n\nLa formulación también es válida en un contexto diferente, en el que:\n\nLa verdadera \\(X\\) es incoherente (hablando aproximadamente, no tiene unos pocos elementos que sean mucho más grandes que los otros)\nLas observaciones \\(A_j\\) son de elementos individuales\n\n\n\n2.4.3 Representación Factorizada\nEn otra forma de regularización, la matriz \\(X\\) se representa explícitamente como un producto de dos matrices “delgadas” \\(L\\) y \\(R\\), donde \\(L \\in \\mathbb{R}^{n \\times r}\\) y \\(R \\in \\mathbb{R}^{p \\times r}\\), con \\(r \\ll \\min(n,p)\\). Establecemos \\(X = LR^T\\) en (Ecuación 2.7) y resolvemos:\n\\[\\min_{L,R} \\frac{1}{2m} \\sum_{j=1}^{m} (\\langle A_j, LR^T \\rangle - y_j)^2 \\tag{2.9}\\]\nEn esta formulación:\n\nEl rango \\(r\\) está “cableado” en la definición de \\(X\\), por lo que no hay necesidad de incluir un término de regularización\nEsta formulación es típicamente mucho más compacta que (Ecuación 2.8); el número total de elementos en \\((L,R)\\) es \\((n + p)r\\), que es mucho menor que \\(np\\)\nSin embargo, esta función es no convexa cuando se considera como una función de \\((L,R)\\) conjuntamente\n\n\n\n\n\n\n\nImportanteNo Convexidad Benigna\n\n\n\nUna línea activa de investigación actual muestra que la no convexidad es benigna en muchas situaciones y que, bajo ciertas suposiciones sobre los datos \\((A_j,y_j)\\), \\(j = 1,2, \\ldots, m\\) y una cuidadosa elección de estrategia algorítmica, se pueden obtener buenas soluciones de la formulación (Ecuación 2.9).\n\n\nUna pista sobre este buen comportamiento es que aunque esta formulación es no convexa, en cierto sentido es una aproximación a un problema tratable: Si tenemos una observación completa de \\(X\\), entonces una aproximación de rango-\\(r\\) puede encontrarse realizando una descomposición de valores singulares de \\(X\\) y definiendo \\(L\\) y \\(R\\) en términos de los \\(r\\) principales vectores singulares izquierdos y derechos.\n\n\n2.4.4 Factorización de Matrices No Negativas\nAlgunas aplicaciones en visión por computadora, quimiometría y agrupamiento de documentos requieren que encontremos factores \\(L\\) y \\(R\\) como aquellos en (Ecuación 2.9) en los que todos los elementos son no negativos. Si se observa la matriz completa \\(Y \\in \\mathbb{R}^{n \\times p}\\), este problema tiene la forma:\n\\[\\min_{L,R} \\|LR^T - Y\\|_F^2 \\quad \\text{sujeto a } L \\geq 0, \\; R \\geq 0 \\tag{2.10}\\]\ny se llama factorización de matrices no negativas.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-svm",
    "href": "chapters/optimization/01_intro.html#sec-svm",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.5 Máquinas de Vectores de Soporte",
    "text": "2.5 Máquinas de Vectores de Soporte\n\n\n\n\n\n\nNotaProblema Clásico de ML\n\n\n\nLa clasificación mediante Máquinas de Vectores de Soporte (SVM) es un problema de optimización clásico en aprendizaje automático, que remonta sus orígenes a la década de 1960.\n\n\nDados los datos de entrada \\((a_j,y_j)\\) con \\(a_j \\in \\mathbb{R}^n\\) e \\(y_j \\in \\{-1,1\\}\\), SVM busca un vector \\(x \\in \\mathbb{R}^n\\) y un escalar \\(\\beta \\in \\mathbb{R}\\) tales que:\n\\[a_j^T x - \\beta \\geq 1 \\quad \\text{cuando } y_j = +1 \\tag{2.11}\\]\n\\[a_j^T x - \\beta \\leq -1 \\quad \\text{cuando } y_j = -1 \\tag{2.12}\\]\nCualquier par \\((x,\\beta)\\) que satisfaga estas condiciones define un hiperplano separador en \\(\\mathbb{R}^n\\), que separa los casos “positivos” \\(\\{a_j \\mid y_j = +1\\}\\) de los casos “negativos” \\(\\{a_j \\mid y_j = -1\\}\\).\nEntre todos los hiperplanos separadores, el que minimiza \\(\\|x\\|_2\\) es el que maximiza el margen entre las dos clases – es decir, el hiperplano cuya distancia al punto \\(a_j\\) más cercano de cualquier clase es mayor.\n\n2.5.1 Formulación de Pérdida Bisagra\nPodemos formular el problema de encontrar un hiperplano separador como un problema de optimización definiendo un objetivo con la forma de suma (Ecuación 2.2):\n\\[H(x,\\beta) = \\frac{1}{m} \\sum_{j=1}^{m} \\max(1 - y_j(a_j^T x - \\beta), 0) \\tag{2.13}\\]\nNótese que el término \\(j\\)-ésimo en esta suma es cero si se satisfacen las condiciones (Ecuación 2.11)–(Ecuación 2.12), y es positivo en caso contrario. Incluso si no existe ningún par \\((x,\\beta)\\) para el cual \\(H(x,\\beta) = 0\\), un valor \\((x,\\beta)\\) que minimice (Ecuación 2.13) será el que más se acerque a satisfacer las condiciones en algún sentido.\nA menudo se agrega un término \\(\\frac{1}{2\\lambda}\\|x\\|_2^2\\) (para algún parámetro \\(\\lambda &gt; 0\\)) a (Ecuación 2.13), produciendo la siguiente versión regularizada:\n\\[H(x,\\beta) = \\frac{1}{m} \\sum_{j=1}^{m} \\max(1 - y_j(a_j^T x - \\beta), 0) + \\frac{1}{2\\lambda}\\|x\\|_2^2 \\tag{2.14}\\]\n\n\n\n\n\n\nNotaPérdida vs Regularizador\n\n\n\nEn contraste con los ejemplos presentados hasta ahora, el problema SVM tiene una función de pérdida no suave y un regularizador suave.\n\n\nSi \\(\\lambda\\) es suficientemente pequeño, y si existen hiperplanos separadores, el par \\((x,\\beta)\\) que minimiza (Ecuación 2.14) es el hiperplano separador de margen máximo. La propiedad de margen máximo es consistente con los objetivos de generalizabilidad y robustez.\nPor ejemplo, si los datos observados \\((a_j,y_j)\\) se extraen de una “nube” subyacente de casos positivos y negativos, la solución de margen máximo generalmente hace un trabajo razonable al separar otras muestras de datos empíricos extraídas de las mismas nubes, mientras que un hiperplano que pasa cerca de varios de los puntos de datos observados puede no funcionar tan bien.\n\n\n2.5.2 Métodos de Kernel\nA menudo, no es posible encontrar un hiperplano que separe los casos positivos y negativos lo suficientemente bien como para ser útil como clasificador. Una solución es transformar todos los vectores de datos brutos \\(a_j\\) mediante algún mapeo no lineal \\(\\psi\\) y luego realizar la clasificación de máquina de vectores de soporte en los vectores \\(\\psi(a_j)\\), \\(j = 1,2, \\ldots, m\\). Las condiciones (Ecuación 2.11)–(Ecuación 2.12) serían así reemplazadas por:\n\\[\\psi(a_j)^T x - \\beta \\geq 1 \\quad \\text{cuando } y_j = +1 \\tag{2.15}\\]\n\\[\\psi(a_j)^T x - \\beta \\leq -1 \\quad \\text{cuando } y_j = -1 \\tag{2.16}\\]\nconduciendo al siguiente análogo de (Ecuación 2.14):\n\\[H(x,\\beta) = \\frac{1}{m} \\sum_{j=1}^{m} \\max(1 - y_j(\\psi(a_j)^T x - \\beta), 0) + \\frac{1}{2\\lambda}\\|x\\|_2^2 \\tag{2.17}\\]\nCuando se transforma de vuelta a \\(\\mathbb{R}^m\\), la superficie \\(\\{a \\mid \\psi(a)^T x - \\beta = 0\\}\\) es no lineal y posiblemente desconectada, y a menudo es un clasificador mucho más poderoso que los hiperplanos resultantes de (Ecuación 2.14).\n\n\n2.5.3 Formulación Dual\nNotamos que SVM también puede expresarse naturalmente como un problema de minimización sobre un conjunto convexo. Al introducir variables artificiales, el problema (Ecuación 2.17) (y (Ecuación 2.14)) puede formularse como un programa cuadrático convexo – es decir, un problema con un objetivo cuadrático convexo y restricciones lineales.\nAl tomar el dual de este problema, obtenemos otro programa cuadrático convexo, en \\(m\\) variables:\n\\[\\begin{aligned}\n\\min_{\\alpha \\in \\mathbb{R}^m} \\quad & \\frac{1}{2}\\alpha^T Q\\alpha - \\mathbf{1}^T \\alpha \\\\\n\\text{sujeto a} \\quad & 0 \\leq \\alpha \\leq \\frac{1}{\\lambda}\\mathbf{1}, \\quad y^T \\alpha = 0\n\\end{aligned} \\tag{2.18}\\]\ndonde:\n\n\\(Q_{kl} = y_k y_l \\psi(a_k)^T \\psi(a_l)\\)\n\\(y = (y_1, y_2, \\ldots, y_m)^T\\)\n\n\\(\\mathbf{1} = (1, 1, \\ldots, 1)^T\\)\n\n\n\n\n\n\n\nImportanteEl Truco del Kernel\n\n\n\nCuriosamente, el problema (Ecuación 2.18) puede formularse y resolverse sin conocimiento o definición explícita del mapeo \\(\\psi\\). Solo necesitamos una técnica para definir los elementos de \\(Q\\). Esto se puede hacer con el uso de una función kernel \\(K : \\mathbb{R}^n \\times \\mathbb{R}^n \\to \\mathbb{R}\\), donde \\(K(a_k,a_l)\\) reemplaza \\(\\psi(a_k)^T \\psi(a_l)\\). Este es el llamado truco del kernel.\n\n\nLa función kernel \\(K\\) también puede usarse para construir una función de clasificación \\(\\phi\\) a partir de la solución de (Ecuación 2.18). Una elección particularmente popular de kernel es el kernel Gaussiano:\n\\[K(a_k,a_l) := \\exp\\left(-\\frac{1}{2\\sigma^2} \\|a_k - a_l\\|_2^2\\right) \\tag{2.19}\\]\ndonde \\(\\sigma\\) es un parámetro positivo.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-logistic-regression",
    "href": "chapters/optimization/01_intro.html#sec-logistic-regression",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.6 Regresión Logística",
    "text": "2.6 Regresión Logística\nLa regresión logística puede verse como una forma suavizada de clasificación binaria de máquina de vectores de soporte en la que, en lugar de que la función de clasificación \\(\\phi\\) dé una predicción sin calificar de la clase en la que se encuentra un nuevo vector de datos \\(a\\), devuelve una estimación de las probabilidades de que \\(a\\) pertenezca a una clase u otra.\nBuscamos una “función de probabilidades” \\(p\\) parametrizada por un vector \\(x \\in \\mathbb{R}^n\\):\n\\[p(a;x) := (1 + \\exp(a^T x))^{-1} \\tag{2.20}\\]\ny buscamos elegir el parámetro \\(x\\) de modo que:\n\n\\(p(a_j;x) \\approx 1\\) cuando \\(y_j = +1\\)\n\\(p(a_j;x) \\approx 0\\) cuando \\(y_j = -1\\)\n\nNótese la similitud con (Ecuación 2.11)–(Ecuación 2.12).\n\n2.6.1 Logaritmo Negativo de Verosimilitud\nEl valor óptimo de \\(x\\) puede encontrarse minimizando una función de logaritmo negativo de verosimilitud:\n\\[L(x) := -\\frac{1}{m} \\left[ \\sum_{j:y_j=-1} \\log(1 - p(a_j;x)) + \\sum_{j:y_j=1} \\log p(a_j;x) \\right] \\tag{2.21}\\]\nNótese que la definición (Ecuación 2.20) asegura que \\(p(a;x) \\in (0,1)\\) para todos \\(a\\) y \\(x\\); por lo tanto, \\(\\log(1 - p(a_j;x)) &lt; 0\\) y \\(\\log p(a_j;x) &lt; 0\\) para todos \\(j\\) y todos \\(x\\). Cuando se satisfacen las condiciones anteriores, estos términos logarítmicos serán solo ligeramente negativos, por lo que los valores de \\(x\\) que los satisfacen estarán cerca del óptimo.\n\n\n2.6.2 Selección de Características con LASSO\nPodemos realizar selección de características usando el modelo (Ecuación 2.21) introduciendo un regularizador \\(\\lambda \\|x\\|_1\\) (como en la técnica LASSO para mínimos cuadrados):\n\\[\\min_x -\\frac{1}{m} \\left[ \\sum_{j:y_j=-1} \\log(1 - p(a_j;x)) + \\sum_{j:y_j=1} \\log p(a_j;x) \\right] + \\lambda\\|x\\|_1 \\tag{2.22}\\]\ndonde \\(\\lambda &gt; 0\\) es un parámetro de regularización. Este término tiene el efecto de producir una solución en la que pocos componentes de \\(x\\) son no nulos, haciendo posible evaluar \\(p(a;x)\\) conociendo solo aquellos componentes de \\(a\\) que corresponden a los no nulos en \\(x\\).\n\n\n2.6.3 Regresión Logística Multiclase\nUna extensión importante de esta técnica es a la regresión logística multiclase (o multinomial), en la que los vectores de datos \\(a_j\\) pertenecen a más de dos clases. Tales aplicaciones son comunes en el análisis de datos moderno.\n\n\n\n\n\n\nTipEjemplo: Reconocimiento de Voz\n\n\n\nEn un sistema de reconocimiento de voz, las \\(M\\) clases podrían representar cada una un fonema del habla, uno de los potencialmente miles de sonidos elementales distintos que pueden ser pronunciados por humanos en unas pocas decenas de milisegundos.\n\n\nUn problema de regresión logística multinomial requiere una función de probabilidades distinta \\(p_k\\) para cada clase \\(k \\in \\{1,2, \\ldots, M\\}\\). Estas funciones se parametrizan mediante vectores \\(x^{[k]} \\in \\mathbb{R}^n\\), \\(k = 1,2, \\ldots, M\\), definidos como sigue:\n\\[p_k(a;X) := \\frac{\\exp(a^T x^{[k]})}{\\sum_{l=1}^{M} \\exp(a^T x^{[l]})}, \\quad k = 1,2, \\ldots, M \\tag{2.23}\\]\ndonde definimos \\(X := \\{x^{[k]} \\mid k = 1,2, \\ldots, M\\}\\).\nComo en el caso binario, tenemos \\(p_k(a) \\in (0,1)\\) para todos \\(a\\) y todos \\(k = 1,2, \\ldots, M\\) y, además, que \\(\\sum_{k=1}^{M} p_k(a) = 1\\). Las funciones (Ecuación 2.23) realizan un “softmax” en las cantidades \\(\\{a^T x^{[l]} \\mid l = 1,2, \\ldots, M\\}\\).\nEn el contexto de la regresión logística multiclase, las etiquetas \\(y_j\\) son vectores en \\(\\mathbb{R}^M\\) cuyos elementos se definen como sigue:\n\\[y_{jk} = \\begin{cases}\n1 & \\text{cuando } a_j \\text{ pertenece a la clase } k, \\\\\n0 & \\text{en caso contrario.}\n\\end{cases} \\tag{2.24}\\]\nDe manera similar al caso binario, buscamos definir los vectores \\(x^{[k]}\\) de modo que:\n\n\\(p_k(a_j;X) \\approx 1\\) cuando \\(y_{jk} = 1\\)\n\\(p_k(a_j;X) \\approx 0\\) cuando \\(y_{jk} = 0\\)\n\nEl problema de encontrar valores de \\(x^{[k]}\\) que satisfagan estas condiciones puede formularse nuevamente como uno de minimizar un logaritmo negativo de verosimilitud:\n\\[L(X) := -\\frac{1}{m} \\sum_{j=1}^{m} \\left[ \\sum_{\\ell=1}^{M} y_{j\\ell}(x^{[\\ell]T}a_j) - \\log \\left( \\sum_{\\ell=1}^{M} \\exp(x^{[\\ell]T}a_j) \\right) \\right] \\tag{2.25}\\]\nSe pueden incluir términos de regularización de “dispersión grupal” en esta formulación para seleccionar un conjunto de características en los vectores \\(a_j\\), común a cada clase, que distingan efectivamente entre las clases.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-deep-learning",
    "href": "chapters/optimization/01_intro.html#sec-deep-learning",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.7 Aprendizaje Profundo",
    "text": "2.7 Aprendizaje Profundo\nLas redes neuronales profundas a menudo están diseñadas para realizar la misma función que la regresión logística multiclase – es decir, clasificar un vector de datos \\(a\\) en una de \\(M\\) clases posibles, a menudo para \\(M\\) grande. La innovación principal es que el mapeo \\(\\phi\\) del vector de datos a la predicción es ahora una función no lineal, parametrizada explícitamente por un conjunto de transformaciones estructuradas.\n\n2.7.1 Estructura de la Red Neuronal\nLa red neuronal mostrada en forma conceptual ilustra la estructura de una red neuronal particular. En esta estructura:\n\nEl vector de datos \\(a_j\\) entra por la izquierda de la red\nCada caja (más a menudo referida como una “capa”) representa una transformación que toma un vector de entrada y aplica una transformación no lineal de los datos para producir un vector de salida\nLa salida de cada operador se convierte en la entrada para una o más capas subsiguientes\nCada capa tiene su propio conjunto de parámetros, y la colección de todos los parámetros sobre todas las capas comprende nuestra variable de optimización\nLos diferentes tipos de transformaciones pueden diferir entre capas, pero podemos componerlas de la manera que se adapte a nuestra aplicación\n\n\n\n2.7.2 Transformaciones de Capa\nUna transformación típica, que convierte el vector \\(a_j^{l-1}\\) que representa la salida de la capa \\(l-1\\) al vector \\(a_j^l\\) que representa la salida de la capa \\(l\\), es:\n\\[a_j^l = \\sigma(W^l a_j^{l-1} + g^l) \\tag{2.26}\\]\ndonde:\n\n\\(W^l\\) es una matriz de dimensión \\(|a_j^l| \\times |a_j^{l-1}|\\)\n\\(g^l\\) es un vector de longitud \\(|a_j^l|\\)\n\\(\\sigma\\) es una transformación no lineal componente a componente, usualmente llamada función de activación\n\nLas formas más comunes de la función de activación \\(\\sigma\\) actúan independientemente en cada componente de su vector de argumento como sigue:\n\nSigmoide: \\(t \\to 1/(1 + e^{-t})\\)\nUnidad Lineal Rectificada (ReLU): \\(t \\to \\max(t,0)\\)\n\nSe necesitan transformaciones alternativas cuando la entrada a la caja \\(l\\) proviene de dos o más cajas precedentes.\n\n\n2.7.3 Capa de Salida y Función de Pérdida\nLa capa más a la derecha de la red neuronal (la capa de salida) típicamente tiene \\(M\\) salidas, una para cada una de las posibles clases a las que la entrada (\\(a_j\\), digamos) podría pertenecer. Estas se comparan con las etiquetas \\(y_{jk}\\), definidas como en (Ecuación 2.24) para indicar a cuál de las \\(M\\) clases pertenece \\(a_j\\). A menudo, se aplica un softmax a las salidas en la capa más a la derecha, y se obtiene una función de pérdida similar a (Ecuación 2.25).\n\n\n2.7.4 Problema de Optimización en Aprendizaje Profundo\nConsideremos el caso especial (pero no infrecuente) en el que la estructura de la red neuronal es un grafo lineal de \\(D\\) niveles, en el que la salida de la capa \\(l-1\\) se convierte en la entrada de la capa \\(l\\) (para \\(l = 1,2, \\ldots, D\\)) con \\(a_j = a_j^0\\), \\(j = 1,2, \\ldots, m\\), y la transformación dentro de cada caja tiene la forma (Ecuación 2.26). Se aplica un softmax a la salida de la capa más a la derecha para obtener un conjunto de probabilidades.\nLos parámetros en esta red neuronal son los pares matriz-vector \\((W^l,g^l)\\), \\(l = 1,2, \\ldots, D\\) que transforman el vector de entrada \\(a_j = a_j^0\\) en la salida \\(a_j^D\\) de la capa final. Buscamos elegir todos estos parámetros de modo que la red haga un buen trabajo al clasificar correctamente los datos de entrenamiento.\nUsando la notación \\(w\\) para las transformaciones capa a capa, es decir:\n\\[w := (W^1,g^1,W^2,g^2, \\ldots, W^D,g^D)\\]\npodemos escribir la función de pérdida para aprendizaje profundo como:\n\\[L(w) = -\\frac{1}{m} \\sum_{j=1}^{m} \\left[ \\sum_{\\ell=1}^{M} y_{j\\ell} a_{j,\\ell}^D(w) - \\log \\left( \\sum_{\\ell=1}^{M} \\exp a_{j,\\ell}^D(w) \\right) \\right] \\tag{2.27}\\]\ndonde \\(a_{j,\\ell}^D(w) \\in \\mathbb{R}\\) es la salida del elemento \\(\\ell\\)-ésimo en la capa \\(D\\) correspondiente al vector de entrada \\(a_j^0\\). (Aquí escribimos \\(a_{j,\\ell}^D(w)\\) para hacer explícita la dependencia de las transformaciones \\(w\\) así como del vector de entrada \\(a_j\\).)\nPodemos ver la regresión logística multiclase como un caso especial de aprendizaje profundo con \\(D = 1\\), de modo que \\(a_{j,\\ell}^1 = W_{\\ell,\\cdot}^1 a_j^0\\), donde \\(W_{\\ell,\\cdot}^1\\) denota la fila \\(\\ell\\) de la matriz \\(W^1\\).\n\n\n2.7.5 Variantes e Ingeniería\nLas redes neuronales en uso para aplicaciones particulares (por ejemplo, en reconocimiento de imagen y reconocimiento de voz, donde han tenido bastante éxito) incluyen muchas variantes del diseño básico. Estas incluyen:\n\nConectividad restringida entre las cajas (que corresponde a imponer estructura de dispersión en las matrices \\(W^l\\), \\(l = 1,2, \\ldots, D\\))\nCompartir parámetros, que corresponde a forzar subconjuntos de los elementos de \\(W^l\\) a tomar el mismo valor\nArreglos complejos de las cajas, con salidas provenientes de varias capas, conexiones a través de capas no adyacentes, diferentes transformaciones componente a componente \\(\\sigma\\) en diferentes capas, y así sucesivamente\n\nLas redes neuronales profundas para aplicaciones prácticas son objetos altamente diseñados.\n\n\n2.7.6 Características Distintivas del Aprendizaje Profundo\nLa función de pérdida (Ecuación 2.27) comparte con muchas otras aplicaciones la forma de suma finita (Ecuación 2.2), pero tiene varias características que la distinguen de las otras aplicaciones discutidas anteriormente:\n\nNo Convexidad: Lo más importante, es no convexa en los parámetros \\(w\\)\nGran Escala: El número total de parámetros en \\(w\\) es usualmente muy grande\n\nEl entrenamiento efectivo de clasificadores de aprendizaje profundo típicamente requiere una gran cantidad de datos y poder de cómputo. Enormes clústeres de computadoras potentes – a menudo usando procesadores multinúcleo, GPUs, e incluso unidades de procesamiento especialmente arquitecturadas – se dedican a esta tarea.",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "chapters/optimization/01_intro.html#sec-emphasis",
    "href": "chapters/optimization/01_intro.html#sec-emphasis",
    "title": "2  Introducción a la Optimización para Ciencia de Datos",
    "section": "2.8 Énfasis",
    "text": "2.8 Énfasis\nMuchos problemas pueden formularse como en el marco (Ecuación 2.3), y sus propiedades pueden diferir significativamente. Podrían ser convexos o no convexos, y suaves o no suaves. Pero hay características importantes que todos comparten:\n\n\n\n\n\n\nNotaCaracterísticas Compartidas de los Problemas de Optimización\n\n\n\n\nPueden formularse como funciones de variables reales, que típicamente organizamos en un vector de longitud \\(n\\)\nLas funciones son continuas. Cuando aparece no suavidad en la formulación, lo hace de manera estructurada que puede ser explotada por el algoritmo\nLas propiedades de suavidad permiten a un algoritmo hacer buenas inferencias sobre el comportamiento de la función basándose en el conocimiento obtenido en puntos cercanos que han sido visitados previamente\nEl objetivo a menudo se compone en parte de una suma de muchos términos, donde cada término depende de un único elemento de datos\nEl objetivo es a menudo una suma de dos términos: un “término de pérdida” (a veces surgiendo de una expresión de máxima verosimilitud para algún modelo estadístico) y un “término de regularización” cuyo propósito es imponer estructura y “generalizabilidad” en el modelo recuperado\n\n\n\n\n2.8.1 Énfasis del Tratamiento\nNuestro tratamiento enfatiza algoritmos para resolver estos diversos tipos de problemas, con análisis de las propiedades de convergencia de estos algoritmos. Prestamos atención a las garantías de complejidad, que son límites en la cantidad de esfuerzo computacional requerido para obtener soluciones de una precisión dada. Estos límites usualmente dependen de propiedades fundamentales de la función objetivo y los datos que la definen, incluyendo:\n\nLas dimensiones del conjunto de datos\nEl número de variables en el problema\n\nEste énfasis contrasta con gran parte de la literatura de optimización, en la que los resultados de convergencia global usualmente no involucran límites de complejidad. (Una excepción notable es el análisis de métodos de punto interior.)\n\n\n2.8.2 Preocupaciones Prácticas\nAl mismo tiempo, tratamos en la medida de lo posible de enfatizar las preocupaciones prácticas asociadas con la resolución de estos problemas. Hay una variedad de compromisos presentados por cualquier problema, y el optimizador tiene que evaluar qué herramientas son más apropiadas para usar. Además de la formulación del problema, es imperativo tener en cuenta:\n\nEl presupuesto de tiempo para la tarea en cuestión\nEl tipo de computadora en la que se resolverá el problema\nLas garantías necesarias para la solución",
    "crumbs": [
      "Métodos de Optimización",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la Optimización para Ciencia de Datos</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Resumen y Referencias",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "Resumen y Referencias",
      "References"
    ]
  }
]